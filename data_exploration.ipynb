{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f2034b",
   "metadata": {},
   "source": [
    "# Annual Business Survey 2019\n",
    "## Group Assessment - Module 08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e777469",
   "metadata": {
    "tags": []
   },
   "source": [
    "  *****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ba20f",
   "metadata": {},
   "source": [
    "## ETL Report\n",
    "### Introduction\n",
    "\n",
    "- In this portion, we will dicuss the problems or questions that we are trying to solve or answer. \n",
    "    We will identify the sources of our data and describe why the data needs to be transformed.\n",
    "    \n",
    "The United States Census Bureau provides access to an extensive database with hundreds of datasets that detail national <br>\n",
    "  characteristics. The data is stored in a way that can be quite confusing to many people, but there are many resources to <br>\n",
    "  assist interested researchers with gleaning new insights from the data.\n",
    "  \n",
    "For this study, we looked specifically at the Annual Business Survey for **2019** which examines data from **2018**. This survey <br>\n",
    "  provides information on a variety of characteristics for businesses and business owners.\n",
    "  \n",
    "**These are the questions that we are focusing on:**<br>\n",
    "> 1. When considering the Finance and Insurance Industries as well as the Education Industry, what are the reasons that a owner <br>\n",
    "      was motivated to create the business?\n",
    "      \n",
    "> 2. When considering the highest average pay for each state, are there any noticeable trends when accounting for the Industry, <br>\n",
    "      the Race of the Owner, or the Gender of the Owner?\n",
    "\n",
    "> 3. What are some of the most popular tech solutions in Minnesota?\n",
    "    \n",
    "> 4. What questions are business owners most likely to respond to?\n",
    "\n",
    "> 5. Is there a gender gap among business owners based on race?\n",
    "\n",
    "> 6. Is there significant variance in new businesses across the country, and if so, which states have a higher portion of new businesses?\n",
    "\n",
    "> 7. For the states with the highest contrast in portion of new businesses, which categories with years in business are making up the difference?\n",
    "\n",
    "> 8. Which industries have the highest portion of new businesses, and does this help explain location variance?\n",
    "\n",
    "> 9. What trends are there in the ownership of firms by gender, and is it significantly different across industries?\n",
    "\n",
    "> 10. What are the trends for ownership of firms by racial group, and how does this compare to overall US demographics?\n",
    "\n",
    "\n",
    "**Why is it important to transform the data?**<br>\n",
    "\n",
    "As mentioned previously, the data is stored in a way that can be quite confusing, and it is necessary to perform a variety of<br>\n",
    "  transformations on it before it can be utilized. Some things to keep in mind is that there are multiple series of \"total\" categories,<br>\n",
    "  multiple variables stored in a single column, and the call to the API must contain every needed variable, as well as supporting variables<br>\n",
    "  in order to get complete and accurate results.\n",
    "### Data Sources\n",
    "\n",
    "The data used in this study was gathered directly from the U.S. Census Bureau data API. \n",
    "\n",
    ">US Census Bureau. (2021b, October 14). *Annual Business Survey (ABS) APIs.* Census.Gov.<br>\n",
    ">Retrieved April 22, 2022, from https://www.census.gov/data/developers/data-sets/abs.2019.html\n",
    "\n",
    "### Extraction\n",
    "\n",
    "- In this portion we will show how we got our data, show aspects of the data consumption process and indicate the order of the process.\n",
    "**Step 1 - Import Modules**\n",
    "> In this step, we are gathering all the modules that will be used in the script. We have also included a helper module that can act <br>\n",
    "as a variable dictionary for someone seeking to understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abcdd8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- HELPER MODULE IMPORTED ------\n",
      "\n",
      "    For information on the helper module:\n",
      "        run 'help(explain)' in any cell. \n",
      "        \n",
      "    To directly use:\n",
      "        run 'explain.what_is()' with no parameters.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from textwrap import wrap\n",
    "from utils import explain # Helper for clarifying variable information (for questions about this, type \"help(explain)\" in a cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea13228",
   "metadata": {},
   "source": [
    "**Step 2 - Get Variable Tables**\n",
    "> In this step, we gathered the variables from each of the available datasets, and merged them into a single table with a goal<br>\n",
    "of understanding what data was available in each table, and if there were any common variables between tables.\n",
    "\n",
    "> To read this data into a dataframe we used the Pandas **\"read_html()\"** method which returns a list of all tables that are<br>\n",
    "that are available at the target source. We then kept only the first two columns from each table and renamed a column<br>\n",
    "that would cause name conflicts in a merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aea97e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_links = [\n",
    "    'https://api.census.gov/data/2018/abstcb/variables.html',\n",
    "    'https://api.census.gov/data/2018/abscbo/variables.html',\n",
    "    'https://api.census.gov/data/2018/abscb/variables.html',\n",
    "    'https://api.census.gov/data/2018/abscs/variables.html'\n",
    "]\n",
    "\n",
    "# Get the tables of variables.\n",
    "tech_vars = pd.read_html(var_links[0])[0]\n",
    "owner_vars = pd.read_html(var_links[1])[0]\n",
    "characteristic_vars = pd.read_html(var_links[2])[0]\n",
    "company_summary_vars = pd.read_html(var_links[3])[0]\n",
    "\n",
    "# Keep only two columns from each table and rename columns for merge.\n",
    "tech_vars = tech_vars.iloc[:,:2\n",
    "                        ].rename(columns = {'Label': 'Tech Labels'})\n",
    "\n",
    "owner_vars = owner_vars.iloc[:,:2\n",
    "                        ].rename(columns = {'Label': 'Owner Labels'})\n",
    "\n",
    "characteristic_vars = characteristic_vars.iloc[:,:2\n",
    "                        ].rename(columns = {'Label': 'Characteristic Labels'})\n",
    "\n",
    "company_summary_vars = company_summary_vars.iloc[:,:2\n",
    "                        ].rename(columns = {'Label': 'Company Summary Labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08cf40",
   "metadata": {},
   "source": [
    "**Step 3 - Merge Variable Tables**\n",
    "> In this step we merged all the variable tables using a full outer merge so that all records would<br>\n",
    "be retained. We also filled all the null cells that were generated in the merge with \"-\" so that the<br>\n",
    "table would be easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a44db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tables = pd.merge(\n",
    "    tech_vars, owner_vars, left_on = 'Name', right_on = 'Name', how = 'outer'\n",
    ")\n",
    "\n",
    "grouped_tables = pd.merge(\n",
    "    grouped_tables, characteristic_vars, left_on = 'Name', right_on = 'Name', how = 'outer'\n",
    ")\n",
    "\n",
    "grouped_tables = pd.merge(\n",
    "    grouped_tables, company_summary_vars, left_on = 'Name', right_on = 'Name', how = 'outer'\n",
    ")\n",
    "\n",
    "grouped_tables.fillna(\"-\", inplace = True)\n",
    "grouped_tables = grouped_tables[(~grouped_tables['Name'].str.endswith('_S'))]\n",
    "\n",
    "grouped_tables = grouped_tables[:-2].sort_values(by = 'Name')\n",
    "grouped_tables = grouped_tables[(~grouped_tables['Name'].str.contains('variables'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e464c",
   "metadata": {},
   "source": [
    "**Step 4 - Group Similar Variables**\n",
    "> This step was necessary because some of the variables referenced the same metric<br>\n",
    "but were named slightly differently. For example, OWNER_ETH vs. ETH_GROUP. \n",
    "\n",
    "> We then ordered the generated table by column and by name to prepare it for<br>\n",
    "further use.\n",
    "\n",
    "> We created a smaller table from this generated table that consisted only of<br>\n",
    "the variables that were present in all datsets. This was done in an effort to<br>\n",
    "reduce the ambiguity of the datasets and inform a merge of all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3feea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_var_names(var_name):\n",
    "    \"\"\" This function assists with grouping similar variables \"\"\"\n",
    "    if 'OWNER_' in var_name:\n",
    "        var_name = var_name.replace('OWNER_',\"\")\n",
    "    elif ('OWN' in var_name and 'CHAR' not in var_name and 'PDEMP' not in var_name):\n",
    "        var_name = var_name.replace('OWN',\"\")\n",
    "    \n",
    "    if var_name in ['ETH','RACE','SEX','VET']:\n",
    "        var_name = var_name + \"_GROUP\"\n",
    "        \n",
    "    return var_name\n",
    "\n",
    "grouped_tables['Common_Vars'] = grouped_tables['Name'].apply(clean_var_names)\n",
    "grouped_tables = grouped_tables[\n",
    "    ['Name','Common_Vars','Tech Labels','Owner Labels',\n",
    "     'Characteristic Labels','Company Summary Labels']\n",
    "]\n",
    "\n",
    "grouped_tables.sort_values(\n",
    "    by = 'Common_Vars').reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Create smaller dataframe that just contains variables present in all tables.\n",
    "possible_merge_options = grouped_tables[\n",
    "    (grouped_tables['Common_Vars'].str.contains(\"SEX|RACE|ETH|VET\")) | \n",
    "    (grouped_tables.apply(lambda x: not x.str.contains(\"-\").any(), axis = 1))\n",
    "].sort_values(by = 'Common_Vars').reset_index(drop = True)\n",
    "\n",
    "# This list contains all variables that were found in the possible_merge_options.\n",
    "common_vars = [_.lower() for _ in possible_merge_options.Common_Vars.unique().tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d542ab7b",
   "metadata": {},
   "source": [
    "**The cell below is intended for viewing the generated dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada9dc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#possible_merge_options\n",
    "#grouped_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795f5db",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Step 5 - Define which variables will be requested from API**\n",
    "> After reviewing the available end points as well as encountering various errors<br>\n",
    "or missing information, we settled on a list of variables that we were interested in<br>\n",
    "and isolated those variables and the tables they were in from our grouped tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a801ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_of_interest = [\n",
    "    'NAICS2017',\n",
    "    'YIBSZFI',\n",
    "    'SEX',\n",
    "    'QDESC',\n",
    "    'NSFSZFI',\n",
    "    'GEO_ID',\n",
    "    'RACE_GROUP',\n",
    "    'BUSCHAR',\n",
    "    'OWNER_RACE',\n",
    "    'OWNER_SEX',\n",
    "    'OWNPDEMP',\n",
    "    'FIRMPDEMP',\n",
    "    'OWNCHAR',\n",
    "    'TECHUSE',\n",
    "    'RCPPDEMP',\n",
    "    'PAYANN',\n",
    "    'EMP'\n",
    "]\n",
    "\n",
    "target_subset = grouped_tables[(grouped_tables['Name'].isin(vars_of_interest))]\n",
    "target_subset = target_subset[['Name','Company Summary Labels','Characteristic Labels','Owner Labels','Tech Labels']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71500785",
   "metadata": {},
   "source": [
    "**Step 6 - Build variable strings for api calls**\n",
    "> In this step, we used our table of variables and which datasets those variables were available in<br>\n",
    "and generated end point strings to pass into the api call. We used a for loop to generate a dictionary<br>\n",
    "of end point strings. We also added the \"_LABEL\" to any of the endpoints that had that option available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a7c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label = [\n",
    "    'OWNPDEMP_LABEL','GEO_ID_LABEL','FIRMPDEMP_LABEL','STATE_LABEL','PAYANN_LABEL',\n",
    "    'EMP_LABEL','RCPPDEMP_LABEL',\n",
    "]\n",
    "variable_dict = {}\n",
    "for i,label in enumerate(target_subset.columns[1:]):\n",
    "    variable_list = []\n",
    "    for item in target_subset[(target_subset[label] != \"-\")].Name.tolist():\n",
    "        variable_list.append(item)\n",
    "        variable_list.append(f'{item}_LABEL')\n",
    "    variable_list = [_ for _ in variable_list if _ not in no_label]\n",
    "    in_table = \"NAME,\" + \",\".join(variable_list)\n",
    "    variable_dict[i] = in_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3b9d8",
   "metadata": {},
   "source": [
    "**Step 7 - Request Data from API**\n",
    "> Using the dictionary of variable strings that was created in step 6, we generated links for each of the datasets and<br>\n",
    "requested the data from the api. For each call to the api, we printed the url that was passed so that we could easily<br>\n",
    "troubleshoot any errors. The final step was to create a list of all the dataframe that would be iterated through for cleaning them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc4294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the operation fails, click the link to see the error.\n",
      "https://api.census.gov/data/2018/abscs?get=NAME,EMP,FIRMPDEMP,GEO_ID,NAICS2017,NAICS2017_LABEL,PAYANN,RACE_GROUP,RACE_GROUP_LABEL,RCPPDEMP,SEX,SEX_LABEL,YIBSZFI,YIBSZFI_LABEL&for=state:* \n",
      "\n",
      "If the operation fails, click the link to see the error.\n",
      "https://api.census.gov/data/2018/abscb?get=NAME,BUSCHAR,BUSCHAR_LABEL,EMP,FIRMPDEMP,GEO_ID,NAICS2017,NAICS2017_LABEL,PAYANN,QDESC,QDESC_LABEL,RACE_GROUP,RACE_GROUP_LABEL,RCPPDEMP,SEX,SEX_LABEL,YIBSZFI,YIBSZFI_LABEL&for=state:* \n",
      "\n",
      "If the operation fails, click the link to see the error.\n",
      "https://api.census.gov/data/2018/abscbo?get=NAME,GEO_ID,NAICS2017,NAICS2017_LABEL,OWNCHAR,OWNCHAR_LABEL,OWNER_RACE,OWNER_RACE_LABEL,OWNER_SEX,OWNER_SEX_LABEL,OWNPDEMP,QDESC,QDESC_LABEL&for=us:*&for=QDESC_LABEL=YRACQBUS \n",
      "\n",
      "If the operation fails, click the link to see the error.\n",
      "https://api.census.gov/data/2018/abstcb?get=NAME,EMP,FIRMPDEMP,GEO_ID,NAICS2017,NAICS2017_LABEL,NSFSZFI,NSFSZFI_LABEL,PAYANN,RACE_GROUP,RACE_GROUP_LABEL,RCPPDEMP,SEX,SEX_LABEL,TECHUSE,TECHUSE_LABEL&for=state:* \n",
      "\n",
      "If the operation fails, click the link to see the error.\n",
      "https://api.census.gov/data/2018/abscbo?get=NAME,GEO_ID,NAICS2017,NAICS2017_LABEL,OWNCHAR,OWNCHAR_LABEL,OWNER_RACE,OWNER_RACE_LABEL,OWNER_SEX,OWNER_SEX_LABEL,OWNPDEMP,QDESC,QDESC_LABEL&for=state:*&OWNCHAR=CG&NAICS2017=00&QDESC=O02 \n",
      "\n",
      "If the operation fails, click the link to see the error.\n",
      "https://api.census.gov/data/2018/abscs?get=NAME,EMP,FIRMPDEMP,GEO_ID,NAICS2017,NAICS2017_LABEL,PAYANN,RACE_GROUP,RACE_GROUP_LABEL,RCPPDEMP,SEX,SEX_LABEL,YIBSZFI,YIBSZFI_LABEL,FIRMPDEMP&for=us:* \n",
      "\n"
     ]
    }
   ],
   "source": [
    "links = [\n",
    "    f'https://api.census.gov/data/2018/abscs?get={variable_dict[0]}&for=state:*',\n",
    "    f'https://api.census.gov/data/2018/abscb?get={variable_dict[1]}&for=state:*',\n",
    "    f'https://api.census.gov/data/2018/abscbo?get={variable_dict[2]}&for=us:*&for=QDESC_LABEL=YRACQBUS',\n",
    "    f'https://api.census.gov/data/2018/abstcb?get={variable_dict[3]}&for=state:*',\n",
    "    f'https://api.census.gov/data/2018/abscbo?get={variable_dict[2]}&for=state:*&OWNCHAR=CG&NAICS2017=00&QDESC=O02',\n",
    "    f'https://api.census.gov/data/2018/abscs?get={variable_dict[0]}&for=us:*' #<-Jed removed extra variable from here\n",
    "]\n",
    "\n",
    "def get_data_frame(url):\n",
    "    print(\"If the operation fails, click the link to see the error.\")\n",
    "    print(url,'\\n')\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "comp_sum_df = get_data_frame(links[0]) # Company Summary\n",
    "bus_char_df = get_data_frame(links[1]) # Business Characteristics\n",
    "bus_own_df = get_data_frame(links[2]) # Business Owners (National Level)\n",
    "bus_tech_df = get_data_frame(links[3]) # Business Tech   \n",
    "slbo = get_data_frame(links[4]) # Business Owners (State Level)\n",
    "comp_sum_natl_df = get_data_frame(links[5]) #Company Summary National"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7870a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection = [comp_sum_df, bus_char_df, bus_own_df, bus_tech_df, slbo, comp_sum_natl_df]      #JAKE ADDED TO THIS LIST\n",
    "df_names = ['comp_sum_df', 'bus_char_df', 'bus_own_df', 'bus_tech_df','slbo', 'comp_sum_natl_df']   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28603ef",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "> Once we had gathered the datasets that we were interested in, we needed to clean the data<br>\n",
    "so that it could be useful for analysis. \n",
    "\n",
    "> We first created a list of columns that could be dropped. These were present because they were<br> \n",
    "required for the actual call in order to get a related column.\n",
    "\n",
    "> We then iterated through our collection of dataframes and cleaned columns that had artifacts from<br>\n",
    "the method of the api call. \n",
    "\n",
    "> Finally, we renamed some ambiguous columns so that their contents would be more clear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee766493",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\n",
    "    'race_group','sex','yibszfi','qdesc','buschar',\n",
    "    'owner_race','owner_sex','us','ownchar'\n",
    "]\n",
    "\n",
    "for df in df_collection:\n",
    "    column_names = [_ for _ in df.columns.tolist()]\n",
    "    new_column_names = [\n",
    "        _.replace(\"[[\",\"\")\n",
    "         .replace('\"',\"\")\n",
    "         .replace(\"]\",\"\")\n",
    "         .lower() for _ in column_names\n",
    "    ]\n",
    "\n",
    "    df.columns = new_column_names\n",
    "    df.drop(columns = [_ for _ in new_column_names if ('unnamed' in _ or _ in drop_list)],inplace = True)\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace(\"[\",\"\").replace('\"',\"\"))\n",
    "    \n",
    "    if 'sex_label' in df.columns:\n",
    "        df.rename(columns = {'sex_label': 'gender'}, inplace = True)\n",
    "    \n",
    "    if 'owner_sex_label' in df.columns:\n",
    "        df.rename(columns = {'owner_sex_label': 'gender'}, inplace = True)\n",
    "    \n",
    "    if 'naics2017_label' in df.columns:\n",
    "        df.rename(columns = {'naics2017_label': 'industry'}, inplace = True)\n",
    "        \n",
    "    if 'naics2017' in df.columns:\n",
    "        df.rename(columns = {'naics2017': 'industry_code'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a213f",
   "metadata": {},
   "source": [
    "### Display some info about dataframes and save data\n",
    "- This looks a little rough, but that is because it was used to assist in understanding the data<br>\n",
    "    but it has no utility for the general analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb50ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inform():\n",
    "    for i,df in enumerate(df_collection):\n",
    "        # try:\n",
    "        #     df.to_csv(f'data/{df_names[i]}.csv', index = False)\n",
    "        # except:\n",
    "        #     print(\"Data directory is not present - skipping save\")\n",
    "\n",
    "        print('\\n############# NEW DATAFRAME ################')\n",
    "        print('Displaying column value counts where there are fewer than 10 unique values in the column.')\n",
    "        print(f'\\n---  DataFrame: {df_names[i]} ---------------------')\n",
    "        print(f'Columns: {\", \".join(df.columns.tolist())}\\n')\n",
    "        for column in df:\n",
    "            unique_values = len(df[column].unique().tolist())\n",
    "            if (unique_values < 30 and unique_values > 1):\n",
    "                print(df[column].value_counts())\n",
    "                print(\"\")\n",
    "        print('############# END OF DATAFRAME INFO ################\\n\\n')\n",
    "# inform() # Remove comment to display basic information about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630f184",
   "metadata": {},
   "source": [
    "## All Tables Merge\n",
    " - We certainly had a substantial amount of difficulty with this merge because it was difficult to find ways<br>\n",
    "     that the the data could be useful when fully merged. <br><br> \n",
    "     In this merge set, we are looking at the level of artificial intelligence in all sectors in Minnesota, <br>\n",
    "     and how it relates to how long the company has been in business, and whether it is a family owned business.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Limit table data to \"Total for all sectors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7e3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bus_tech_df = bus_tech_df[(bus_tech_df['industry'] == 'Total for all sectors')]\n",
    "total_bus_own_df = bus_own_df[(bus_own_df['industry'] == 'Total for all sectors')]\n",
    "total_comp_sum_df = comp_sum_df[(comp_sum_df['industry'] == 'Total for all sectors')]\n",
    "total_bus_char_df = bus_char_df[(bus_char_df['industry'] == 'Total for all sectors')]\n",
    "total_slbo = slbo[(slbo['industry'] == 'Total for all sectors')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7993b26",
   "metadata": {},
   "source": [
    "2. Further filter the table data and remove unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66af62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "robotics_in_mn = total_bus_tech_df[(~total_bus_tech_df['techuse_label'].str.contains('Total')) & (total_bus_tech_df['name'] == 'Minnesota') & (total_bus_tech_df['techuse_label'].str.contains('Artificial'))]\n",
    "robotics_in_mn = robotics_in_mn[['name','techuse_label','firmpdemp']]\n",
    "\n",
    "years_in_biz_mn = total_comp_sum_df[(total_comp_sum_df.name == 'Minnesota') & (total_comp_sum_df['yibszfi_label'] != 'All firms') & (total_comp_sum_df['gender'] != 'Total')]\n",
    "years_in_biz_mn = years_in_biz_mn[['name','gender','yibszfi_label','firmpdemp']].drop_duplicates()\n",
    "\n",
    "bus_char_mn = total_bus_char_df[(total_bus_char_df.name == 'Minnesota') & (total_bus_char_df['buschar_label'] != 'All firms')& (total_bus_char_df['buschar_label'] != 'Total reporting') & (total_bus_char_df['qdesc_label'] == 'FAMOWN')]\n",
    "bus_char_mn = bus_char_mn[['name','qdesc_label','buschar_label','firmpdemp']]\n",
    "\n",
    "total_slbo = total_slbo[(total_slbo.name == 'Minnesota')]\n",
    "total_slbo = total_slbo[['name','ownchar_label','ownpdemp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81db8f7",
   "metadata": {},
   "source": [
    "3. Rename similar columns so that they are meaningfull after the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd6cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_in_biz_mn.rename(columns = {'firmpdemp': 'yib_num_firms'}, inplace = True)\n",
    "robotics_in_mn.rename(columns = {'firmpdemp': 'robin_mn_num_firms'}, inplace = True)\n",
    "bus_char_mn.rename(columns = {'firmpdemp': 'bus_char_num_firms'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f289355",
   "metadata": {},
   "source": [
    "4. Merge tables using outer merge to retain all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32c4fabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>yibszfi_label</th>\n",
       "      <th>yib_num_firms</th>\n",
       "      <th>techuse_label</th>\n",
       "      <th>robin_mn_num_firms</th>\n",
       "      <th>qdesc_label</th>\n",
       "      <th>buschar_label</th>\n",
       "      <th>bus_char_num_firms</th>\n",
       "      <th>ownchar_label</th>\n",
       "      <th>ownpdemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Equally male/female</td>\n",
       "      <td>Firms with less than 2 years in business</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence: Don't know</td>\n",
       "      <td>4105</td>\n",
       "      <td>FAMOWN</td>\n",
       "      <td>Item not reported</td>\n",
       "      <td>2293</td>\n",
       "      <td>Before 1980</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Equally male/female</td>\n",
       "      <td>Firms with less than 2 years in business</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence: Don't know</td>\n",
       "      <td>4105</td>\n",
       "      <td>FAMOWN</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>3158</td>\n",
       "      <td>Before 1980</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Equally male/female</td>\n",
       "      <td>Firms with 16 or more years in business</td>\n",
       "      <td>272</td>\n",
       "      <td>Artificial Intelligence: Did not use</td>\n",
       "      <td>95053</td>\n",
       "      <td>FAMOWN</td>\n",
       "      <td>Family-owned</td>\n",
       "      <td>17863</td>\n",
       "      <td>Before 1980</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Equally male/female</td>\n",
       "      <td>Firms with 16 or more years in business</td>\n",
       "      <td>272</td>\n",
       "      <td>Artificial Intelligence: Did not use</td>\n",
       "      <td>95053</td>\n",
       "      <td>FAMOWN</td>\n",
       "      <td>Not family-owned</td>\n",
       "      <td>40870</td>\n",
       "      <td>Before 1980</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Equally male/female</td>\n",
       "      <td>Firms with 16 or more years in business</td>\n",
       "      <td>272</td>\n",
       "      <td>Artificial Intelligence: Did not use</td>\n",
       "      <td>95053</td>\n",
       "      <td>FAMOWN</td>\n",
       "      <td>Item not reported</td>\n",
       "      <td>2293</td>\n",
       "      <td>Before 1980</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Equally male/female</td>\n",
       "      <td>Firms with 16 or more years in business</td>\n",
       "      <td>272</td>\n",
       "      <td>Artificial Intelligence: Did not use</td>\n",
       "      <td>95053</td>\n",
       "      <td>FAMOWN</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>3158</td>\n",
       "      <td>Before 1980</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name               gender  \\\n",
       "1870  Minnesota  Equally male/female   \n",
       "1871  Minnesota  Equally male/female   \n",
       "1872  Minnesota  Equally male/female   \n",
       "1873  Minnesota  Equally male/female   \n",
       "1874  Minnesota  Equally male/female   \n",
       "1875  Minnesota  Equally male/female   \n",
       "\n",
       "                                 yibszfi_label  yib_num_firms  \\\n",
       "1870  Firms with less than 2 years in business              0   \n",
       "1871  Firms with less than 2 years in business              0   \n",
       "1872   Firms with 16 or more years in business            272   \n",
       "1873   Firms with 16 or more years in business            272   \n",
       "1874   Firms with 16 or more years in business            272   \n",
       "1875   Firms with 16 or more years in business            272   \n",
       "\n",
       "                             techuse_label  robin_mn_num_firms qdesc_label  \\\n",
       "1870   Artificial Intelligence: Don't know                4105      FAMOWN   \n",
       "1871   Artificial Intelligence: Don't know                4105      FAMOWN   \n",
       "1872  Artificial Intelligence: Did not use               95053      FAMOWN   \n",
       "1873  Artificial Intelligence: Did not use               95053      FAMOWN   \n",
       "1874  Artificial Intelligence: Did not use               95053      FAMOWN   \n",
       "1875  Artificial Intelligence: Did not use               95053      FAMOWN   \n",
       "\n",
       "          buschar_label  bus_char_num_firms ownchar_label  ownpdemp  \n",
       "1870  Item not reported                2293   Before 1980      3210  \n",
       "1871     Not applicable                3158   Before 1980      3210  \n",
       "1872       Family-owned               17863   Before 1980      3210  \n",
       "1873   Not family-owned               40870   Before 1980      3210  \n",
       "1874  Item not reported                2293   Before 1980      3210  \n",
       "1875     Not applicable                3158   Before 1980      3210  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_tables = pd.merge(years_in_biz_mn, robotics_in_mn, left_on = 'name', right_on = 'name', how = 'outer')\n",
    "joined_tables = pd.merge(joined_tables, bus_char_mn, left_on = 'name', right_on = 'name', how = 'outer')\n",
    "joined_tables = pd.merge(joined_tables, total_slbo, left_on = 'name', right_on = 'name', how = 'outer')\n",
    "\n",
    "# Just to display a subset of the data\n",
    "joined_tables.iloc[[_ for _ in range(1870,1876)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed35183",
   "metadata": {},
   "source": [
    "****\n",
    "# Analysis and Visualizations\n",
    "> This section contains the code that was used to further transform the data as needed<br>\n",
    "for visualizations and build visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf541afc-9dd1-406d-b85f-4bac2981c41e",
   "metadata": {},
   "source": [
    "### Jed's Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c8d6ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jeds_visuals():\n",
    "    today = dt.datetime.strftime(\n",
    "        dt.datetime.today().date(), '%b %d, %Y'\n",
    "    )\n",
    "    \n",
    "    state_code_path = 'https://raw.githubusercontent.com/jedc4xer/abs_group_assessment/main/data/state_codes.csv'\n",
    "    state_codes = pd.read_csv(state_code_path)\n",
    "     \n",
    "    def clean_data_stacked_bar():\n",
    "        \"\"\" This function prepares the data for the stacked bar chart. \"\"\"\n",
    "\n",
    "        reason_owned = bus_own_df.copy()\n",
    "\n",
    "        # Filter the data so that only the required data is present.\n",
    "        reason_owned = reason_owned[\n",
    "            (reason_owned['qdesc_label'] == 'REASONOWN') &\n",
    "            (~reason_owned['industry'].str.contains('Total')) &\n",
    "            (~reason_owned['gender'].str.contains('All')) &\n",
    "            (reason_owned['ownchar_label'].str.contains(':'))\n",
    "        ]\n",
    "\n",
    "        # Split the 'reason for owning' label into two distinct columns.\n",
    "        reason_owned[['reason','importance']] = reason_owned.apply(\n",
    "            lambda row: row['ownchar_label'\n",
    "                           ].split(\":\"), axis = 1, result_type = 'expand'\n",
    "        )\n",
    "\n",
    "        #grouped_reason = reason_owned.copy()\n",
    "\n",
    "        # Calculate the total number of responses per reason.\n",
    "        reason_owned = reason_owned.groupby(\n",
    "            by = ['industry','reason','importance'])[['ownpdemp']].agg(\n",
    "            responses = ('ownpdemp', 'sum')\n",
    "        )\n",
    "\n",
    "        # Calculate the ratio of reasons that a business was owned.\n",
    "        reason_owned['ratio'] = (100 * (\n",
    "            reason_owned['responses'] / reason_owned.groupby(\n",
    "                level = [0,1])['responses'].transform('sum'))\n",
    "        ).round(2)\n",
    "\n",
    "        reason_owned.reset_index(inplace = True)\n",
    "\n",
    "        subset = reason_owned.copy()\n",
    "\n",
    "        # Filter the data to include only the target industries.\n",
    "        subset = subset[\n",
    "            (subset['industry'].str.contains('inanc|ducati'))\n",
    "        ]\n",
    "\n",
    "        # Sort the data to prepare it for display.\n",
    "        subset.sort_values(\n",
    "            by = ['importance','ratio'], ascending = False, inplace = True\n",
    "        )\n",
    "\n",
    "        # Rename columns to prepare for display.\n",
    "        subset.rename(columns = {'ratio': 'Percent of Total'}, inplace = True)\n",
    "\n",
    "        # Modify the category names so that they will fit between charts.\n",
    "        reasons = subset.reason.unique().tolist()\n",
    "        longest_reason = len(max(reasons, key = len))\n",
    "        new_reasons = {}\n",
    "        for reason in reasons:\n",
    "            old_reason = reason\n",
    "            while len(reason) < longest_reason - 2:\n",
    "                reason = \" \" + reason + \" \"\n",
    "            if len(old_reason) < 10:\n",
    "                reason = \" \" + reason\n",
    "            new_reasons[old_reason] = reason\n",
    "\n",
    "        subset['reason'] = subset['reason'].apply(lambda x: new_reasons[x])\n",
    "        return subset\n",
    "\n",
    "    def stacked_bar():\n",
    "        \"\"\" This function transforms the data and then builds a stacked bar plot. \"\"\"\n",
    "\n",
    "        stacked_bar_subset = clean_data_stacked_bar()\n",
    "        \n",
    "        fig = px.bar(stacked_bar_subset,\n",
    "                     x = 'Percent of Total',\n",
    "                     y = 'reason',\n",
    "                     color = 'importance',\n",
    "                     width = 1300, height = 600,\n",
    "                     orientation = 'h',\n",
    "                     hover_data = ['reason','responses'],\n",
    "                     text = 'Percent of Total',\n",
    "                     facet_col = 'industry',\n",
    "                     facet_col_spacing=0.14\n",
    "                )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title = 'Reasons for Starting a Company',\n",
    "            yaxis_title = None,\n",
    "            title_y = .98,\n",
    "            title_x = 0.003,\n",
    "            title_font_size = 22,\n",
    "            xaxis_title = \"Percent of Total\", \n",
    "            uniformtext_minsize = 13,\n",
    "            uniformtext_mode = 'hide', \n",
    "            paper_bgcolor = 'white', \n",
    "            plot_bgcolor = 'white',\n",
    "            hoverlabel = dict(\n",
    "                bgcolor = 'white',\n",
    "                bordercolor = 'black',\n",
    "                font_size = 14,\n",
    "                font_color = 'black'\n",
    "            ),\n",
    "            legend = dict(\n",
    "                orientation = 'h',\n",
    "                x=0,y=1.15,\n",
    "                font = dict(size=13)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.update_traces(\n",
    "            textposition = 'inside', \n",
    "            insidetextanchor = 'middle',\n",
    "            textfont = {'color': 'white'}\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(side = 'right')\n",
    "        fig.update_xaxes(ticks = 'outside')\n",
    "        fig.update_layout(\n",
    "            margin={\"r\":0,\"t\":90,\"l\":0,\"b\": 90}, dragmode = False\n",
    "        )\n",
    "\n",
    "        fig.for_each_annotation(\n",
    "            lambda a: a.update(text=a.text.split(\"=\")[1])\n",
    "        )\n",
    "\n",
    "        fig.add_annotation(\n",
    "                text = (\n",
    "                    f\"Created by: Jed Dryer | {today} | Source: US Census - 2019 ABS\"\n",
    "                ),\n",
    "                showarrow=False,\n",
    "                x = .70,\n",
    "                y = -.19,\n",
    "                xref='paper',\n",
    "                yref='paper' ,\n",
    "                xanchor='left',\n",
    "                yanchor='bottom',\n",
    "                xshift=-1,\n",
    "                yshift=-3,\n",
    "                font=dict(size=10, color=\"grey\"),\n",
    "                align=\"right\",\n",
    "                )\n",
    "        fig.write_html('visuals/stacked_reasons.html')\n",
    "        print(\"Jed's Stacked Bar Chart Successfully exported to HTML - Filename: 'stacked_reasons.html'\")\n",
    "\n",
    "    \n",
    "    def build_bar_chart():\n",
    "        \"\"\" This function builds a simple bar chart and saves it to a file. \"\"\"\n",
    "        \n",
    "        # Get a subset of the business tech_df.\n",
    "        subset = bus_tech_df[\n",
    "            (bus_tech_df['industry'] == 'Total for all sectors'\n",
    "            )\n",
    "        ][['name','firmpdemp','techuse_label']]\n",
    "        \n",
    "        # Split the technology label into two distinct columns and then filter.\n",
    "        subset[['tech','usage']] = subset.apply(\n",
    "            lambda row: row['techuse_label'].split(\":\"), axis = 1, result_type = 'expand'\n",
    "        )\n",
    "        subset = subset[(subset['usage'].str.contains('Total R|High'))]\n",
    "        subset = subset[(subset['name']) == 'Minnesota'][['firmpdemp','tech','usage']]\n",
    "        \n",
    "        # Transform and aggregate data to determine total respondents and the rate of use.\n",
    "        subset['total_respondents'] = subset.groupby(\n",
    "            by = ['tech']\n",
    "        )['firmpdemp'].transform('max')\n",
    "        \n",
    "        subset = subset[(subset['usage'].str.contains('High use'))]\n",
    "        subset['rate_of_high_use'] = 100 * (subset['firmpdemp'] / subset['total_respondents'])\n",
    "        subset.sort_values(by = 'rate_of_high_use', ascending = False, inplace = True)\n",
    "\n",
    "        fig = plt.figure(figsize = (18,5))\n",
    "\n",
    "        plt.title('Popular Tech Solutions in Minnesota', fontsize = 20, loc = 'left')\n",
    "        ax = sns.barplot(data = subset, x = 'rate_of_high_use', y = 'tech', palette = 'flare',\n",
    "                        edgecolor = 'grey')\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), size = 12)\n",
    "        ax.tick_params(bottom = False)\n",
    "        for c in ax.containers:\n",
    "            labels = []\n",
    "            for v in c:\n",
    "                if (h := v.get_width()) > 14:\n",
    "                    lab = f'{(h/100)*100:0.1f}% of reporting companies'\n",
    "                elif (h := v.get_width()) > .8:\n",
    "                    lab = f'{(h/100)*100:0.1f}%'\n",
    "                else:\n",
    "                    lab = f'{\" \"*16}- {(h/100)*100:0.2f}%'\n",
    "                labels.append(lab)\n",
    "\n",
    "            ax.bar_label(c,labels=labels,label_type = 'center',fontsize = 18,color= 'black', weight = 'bold')\n",
    "        ax.set(xticklabels = [])\n",
    "        sns.despine(left = True, bottom = True)\n",
    "        fig.savefig('visuals/pop_tech.png')\n",
    "        plt.close()\n",
    "        print(\"Jed's Bar Chart Built and Saved -- Filename: 'pop_tech.png'\")\n",
    "    \n",
    "    def clean_for_map(df, target = 'industry'):\n",
    "        if target not in ['gender','race_group_label','industry']:\n",
    "            possible = \", \".join(['gender','race_group_label','industry'])\n",
    "            print(f'You must choose one of: {possible}')\n",
    "            return\n",
    "        label = {'gender': 'Owner Gender','race_group_label': 'Owner Race','industry':'Industry'}[target]\n",
    "\n",
    "        subset = df[(df.payann != 0) & (df.gender != 'Total') & (df.race_group_label != 'Total') & (df.industry_code != '00')]\n",
    "        subset = subset[['name','geo_id',target,'payann','firmpdemp','emp']]\n",
    "        subset['payann'] = subset['payann'] * 1000\n",
    "        subset['avg_pay'] = subset.apply(lambda row: row.payann/row.emp, axis = 1)\n",
    "\n",
    "        subset_agg = subset.groupby(\n",
    "            by = ['name']\n",
    "                )[['avg_pay']].agg(max_pay = ('avg_pay','max'))\n",
    "\n",
    "        subset_agg.reset_index(inplace = True)\n",
    "\n",
    "        grouped = pd.merge(subset, subset_agg, left_on = 'name', right_on = 'name', how = 'left')\n",
    "\n",
    "        grouped = grouped[(grouped.avg_pay == grouped.max_pay)].reset_index(drop = True)\n",
    "        grouped = grouped.sort_values(by = 'name').reset_index(drop = True)\n",
    "        grouped = grouped.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "        grouped = pd.merge(grouped,state_codes, left_on = 'name', right_on = 'State', how = 'left')\n",
    "\n",
    "        grouped = grouped[['name',target,'avg_pay','Postal Abbr.']]\n",
    "\n",
    "        diffs = set(subset_agg.name.tolist()) - set(grouped.name.tolist())\n",
    "        if len(diffs) > 0:\n",
    "            print('There are some states missing.')\n",
    "        return grouped, target, label\n",
    "    \n",
    "    def plot_maps(grouped, target):\n",
    "        grouped, target, label = clean_for_map(grouped, target)\n",
    "\n",
    "        if target == 'gender':\n",
    "            color_scheme = px.colors.qualitative.Plotly[2:]\n",
    "        else:\n",
    "            color_scheme = px.colors.qualitative.Bold\n",
    "\n",
    "        customdata = np.stack((grouped['name'],grouped[target]),axis = -1)\n",
    "\n",
    "        mapfig = px.choropleth(grouped, \n",
    "                               title = f'Highest Average Pay based on {label}',\n",
    "                               locations = 'Postal Abbr.',\n",
    "                               locationmode = \"USA-states\",\n",
    "                               scope = 'usa',\n",
    "                               color = target,\n",
    "                               hover_data = ['name',target,'avg_pay'],\n",
    "                               color_discrete_sequence = color_scheme,\n",
    "                               height = 600,\n",
    "                               width = 1300,\n",
    "                               )\n",
    "\n",
    "        mapfig.add_annotation(\n",
    "            text = (f\"Created by: Jed Dryer<br>{today}<br>Source: US Census - 2019 ABS\"),\n",
    "            showarrow=False,\n",
    "            x = .54,\n",
    "            y = .01,\n",
    "            xref='paper',\n",
    "            yref='paper' ,\n",
    "            xanchor='left',\n",
    "            yanchor='bottom',\n",
    "            xshift=-1,\n",
    "            yshift=-3,\n",
    "            font=dict(size=10, color=\"grey\"),\n",
    "            align=\"right\",\n",
    "            )\n",
    "\n",
    "        mapfig.update_layout(margin={\"r\":3,\"t\":30,\"l\":0,\"b\":10}, dragmode = False)\n",
    "        mapfig.update_layout(title_y = 0.95, title_x = 0.25, title_font_size = 18,\n",
    "                            legend = dict(x=0.9,y=0.6))\n",
    "        mapfig.update_traces(hovertemplate = '<b>State: %{customdata[0]}</b><br>Value: %{customdata[1]}')\n",
    "        mapfig.update_geos(resolution=50,showlakes=True, lakecolor=\"Lightblue\", subunitcolor = 'black')\n",
    "        return mapfig\n",
    "    \n",
    "    def build_maps():\n",
    "        reasons = ['gender','race_group_label','industry']\n",
    "        maps = []\n",
    "        for reason in reasons:\n",
    "            maps.append(plot_maps(comp_sum_df, reason))\n",
    "\n",
    "        with open('visuals/company_pay_maps.html', 'w') as mapfile:\n",
    "            for fig in maps:\n",
    "                mapfile.write(fig.to_html(full_html = False, include_plotlyjs='cdn'))\n",
    "            mapfile.close()\n",
    "        print(\"Jed's Maps Successfully Exported to HTML -- Filename: 'company_pay_maps.html'\")\n",
    "        \n",
    "    build_maps()    \n",
    "    build_bar_chart()\n",
    "    stacked_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9857825f-8829-485d-ba00-ed4868cc1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jed's Maps Successfully Exported to HTML -- Filename: 'company_pay_maps.html'\n",
      "Jed's Bar Chart Built and Saved -- Filename: 'pop_tech.png'\n",
      "Jed's Stacked Bar Chart Successfully exported to HTML - Filename: 'stacked_reasons.html'\n"
     ]
    }
   ],
   "source": [
    "jeds_visuals() # <--- This is the code to create my visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d626802f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'workingDF' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11748/1667048117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mmarjeas_visuals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11748/1667048117.py\u001b[0m in \u001b[0;36mmarjeas_visuals\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmarjeas_visuals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#filtered values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mworkingDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkingDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mworkingDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'firmpdemp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mworkingDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkingDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mworkingDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'yibszfi_label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'All firms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mworkingDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkingDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mworkingDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'race_group_label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Total'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'workingDF' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def marjeas_visuals():\n",
    "    #filtered values \n",
    "    workingDF = workingDF[workingDF['firmpdemp'] != 0]\n",
    "    workingDF = workingDF[workingDF['yibszfi_label'] == 'All firms']\n",
    "    workingDF = workingDF[workingDF['race_group_label'] == 'Total']\n",
    "\n",
    "    workingDF = workingDF[workingDF['industry'] != 'Industries not classified']\n",
    "\n",
    "    #Drop columns\n",
    "    workingDF.drop(['geo_id', 'name', 'industry_code', 'race_group_label', 'yibszfi_label'], axis = 1, inplace = True)\n",
    "\n",
    "    workingDF = workingDF[workingDF['gender'] != 'Total']\n",
    "    workingDF = workingDF[workingDF['industry'] != 'Total for all sectors']\n",
    "\n",
    "\n",
    "    #Visual 1: Number of Responses to Question by Business owner\n",
    "    df_bus_own = df_collection[2]\n",
    "    df_bus_own[df_bus_own['industry']!='Total for all sectors']\n",
    "    df_bus_own = df_bus_own[df_bus_own['gender']!='All owners of respondent firms']\n",
    "    x = df_bus_own[['qdesc_label','gender','geo_id']].groupby(['qdesc_label','gender']).count()\n",
    "    x = x.reset_index()\n",
    "    x.columns = ['qdesc_label', 'gender', 'count']\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    ax = sns.barplot(data = x, x = 'qdesc_label', y = 'count', hue = 'gender',palette = 'Oranges')\n",
    "    ax.set(xlabel =\"Question Codes\", ylabel = \"number of reponses\", title ='Number of Responses to Question by Business owner')\n",
    "    plt.legend(title = \"Gender\", fontsize = 'large', title_fontsize = 20, loc = 2, bbox_to_anchor = (1,1))\n",
    "    plt.xticks(rotation = 70)\n",
    "    plt.show()\n",
    "\n",
    "    #Visual 2: Percentage of Business Owner Responses\n",
    "    x = x.groupby('qdesc_label')['count'].sum().reset_index()\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.pie(x['count'], labels=x['qdesc_label'], autopct='%1.0f%%', pctdistance = 1.1, labeldistance = 1.2)\n",
    "    plt.legend(title = \"\", fontsize = 'medium', title_fontsize = 10, loc = 3, bbox_to_anchor = (2,0))\n",
    "    plt.title('Percentage of Business Owner Responses')\n",
    "    plt.show()\n",
    "\n",
    "    #Visual 3: Number of Business Owner by Race\n",
    "    x = df_bus_own[['owner_race_label','gender','geo_id']].groupby(['owner_race_label','gender']).count().reset_index()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    sns.set(font_scale=2)\n",
    "\n",
    "    ax = sns.barplot(data = x, x = 'owner_race_label', y = 'geo_id', hue = 'gender', palette = 'Oranges')\n",
    "    ax.set_xlabel(\"Race of Business Owner\", fontsize = 30)\n",
    "    ax.set_ylabel(\"Number of Business Owner\", fontsize = 30)\n",
    "    ax.set_title(\"Number of Business Owner by Race\", fontsize = 40)\n",
    "\n",
    "    plt.legend(title = \"Gender\", fontsize = 'large', title_fontsize = 20, loc = 2, bbox_to_anchor = (1,1))\n",
    "\n",
    "    plt.xticks(rotation = 70)\n",
    "    plt.show()\n",
    "\n",
    "marjeas_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I suggest wrapping your entire visualization process in a function while we work on integrating. \n",
    "\n",
    "# For example. \n",
    "\n",
    "def ryans_visuals(comp_sum_df):\n",
    "    working_df=comp_sum_df\n",
    "    \n",
    "    #Dropping unnccessary rows\n",
    "    working_df = working_df[working_df.race_group_label == 'Total']\n",
    "    working_df = working_df[working_df.industry == 'Total for all sectors']\n",
    "    working_df = working_df[working_df.gender == 'Total']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 2 to 3 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 4 to 5 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 6 to 10 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 11 to 15 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 16 or more years in business']\n",
    "\n",
    "\n",
    "    #Dropping unneccessary columns\n",
    "    working_df = working_df.drop(['geo_id','industry_code','industry','race_group_label','gender','state'], axis = 1)\n",
    "    \n",
    "    #Getting % of businesses under 2 years old of total\n",
    "    working_min = working_df.groupby(by = ['name'])[['firmpdemp']].agg('min')\n",
    "    working_max = working_df.groupby(by = ['name'])[['firmpdemp']].agg('max')\n",
    "    workingfinal = ((working_min / working_max) * 100)\n",
    "    \n",
    "    #Dropping States with nulls/zeroes for under 2 year businesses\n",
    "    workingfinal = workingfinal[~(workingfinal == 0).all(axis=1)]\n",
    "    workingfinal.reset_index(inplace=True)\n",
    "    workingfinal2 = workingfinal\n",
    "    workingfinal.rename(columns = {'firmpdemp':'% of Firms < Two Years Old'}, inplace = True)\n",
    "    #State codes for converting to map form\n",
    "    code = {'Alabama': 'AL',\n",
    "        'Alaska': 'AK',\n",
    "        'Arizona': 'AZ',\n",
    "        'Arkansas': 'AR',\n",
    "        'California': 'CA',\n",
    "        'Colorado': 'CO',\n",
    "        'Connecticut': 'CT',\n",
    "        'Delaware': 'DE',\n",
    "        'District of Columbia': 'DC',\n",
    "        'Florida': 'FL',\n",
    "        'Georgia': 'GA',\n",
    "        'Hawaii': 'HI',\n",
    "        'Idaho': 'ID',\n",
    "        'Illinois': 'IL',\n",
    "        'Indiana': 'IN',\n",
    "        'Iowa': 'IA',\n",
    "        'Kansas': 'KS',\n",
    "        'Kentucky': 'KY',\n",
    "        'Louisiana': 'LA',\n",
    "        'Maine': 'ME',\n",
    "        'Maryland': 'MD',\n",
    "        'Massachusetts': 'MA',\n",
    "        'Michigan': 'MI',\n",
    "        'Minnesota': 'MN',\n",
    "        'Mississippi': 'MS',\n",
    "        'Missouri': 'MO',\n",
    "        'Montana': 'MT',\n",
    "        'Nebraska': 'NE',\n",
    "        'Nevada': 'NV',\n",
    "        'New Hampshire': 'NH',\n",
    "        'New Jersey': 'NJ',\n",
    "        'New Mexico': 'NM',\n",
    "        'New York': 'NY',\n",
    "        'North Carolina': 'NC',\n",
    "        'North Dakota': 'ND',\n",
    "        'Ohio': 'OH',\n",
    "        'Oklahoma': 'OK',\n",
    "        'Oregon': 'OR',\n",
    "        'Pennsylvania': 'PA',\n",
    "        'Rhode Island': 'RI',\n",
    "        'South Carolina': 'SC',\n",
    "        'South Dakota': 'SD',\n",
    "        'Tennessee': 'TN',\n",
    "        'Texas': 'TX',\n",
    "        'Utah': 'UT',\n",
    "        'Vermont': 'VT',\n",
    "        'Virginia': 'VA',\n",
    "        'Washington': 'WA',\n",
    "        'West Virginia': 'WV',\n",
    "        'Wisconsin': 'WI',\n",
    "        'Wyoming': 'WY'}\n",
    "    #Updating states with map code\n",
    "    workingfinal['Code'] = workingfinal['name'].map(code)\n",
    "    \n",
    "    #Map information\n",
    "    fig = px.choropleth(workingfinal,\n",
    "                    locations='Code',\n",
    "                    color='% of Firms < Two Years Old',\n",
    "                    color_continuous_scale='spectral_r',\n",
    "                    locationmode='USA-states',\n",
    "                    scope='usa')\n",
    "    fig.add_scattergeo(\n",
    "        locations=workingfinal['Code'],\n",
    "        locationmode='USA-states',\n",
    "        text=workingfinal['Code'],\n",
    "        mode='text')\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={'text':'Percentage of Total Businesses Less Than Two Years Old by State',\n",
    "               'xanchor':'center',\n",
    "               'yanchor':'top',\n",
    "               'x':0.5})\n",
    "    fig\n",
    "    #Second plot ETL\n",
    "    working_df=comp_sum_df\n",
    "    \n",
    "    #Row removal\n",
    "    working_df = working_df[working_df.race_group_label == 'Total']\n",
    "    working_df = working_df[working_df.industry == 'Total for all sectors']\n",
    "    working_df = working_df[working_df.gender == 'Total']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'All firms']\n",
    "    \n",
    "    #Split to two states\n",
    "    working_df1 = working_df[working_df.name == 'Florida']\n",
    "    working_df2 = working_df[working_df.name == 'West Virginia']\n",
    "    \n",
    "    #Dropping columns\n",
    "    working_df1 = working_df1.drop(['geo_id','industry_code','industry','race_group_label','gender','state'], axis = 1)\n",
    "    working_df2 = working_df2.drop(['geo_id','industry_code','industry','race_group_label','gender','state'], axis = 1)\n",
    "    \n",
    "    #Changing from int to float type for aggregates\n",
    "    working_df2['firmpdemp'] = working_df2['firmpdemp'].astype(float)\n",
    "    working_df1['firmpdemp'] = working_df1['firmpdemp'].astype(float)\n",
    "    \n",
    "    #Updating values for average by index\n",
    "    i = 60339\n",
    "    while i < 60345:\n",
    "        working_df1['firmpdemp'][i] = (working_df1['firmpdemp'][i] * .000223532620)\n",
    "        i = i + 1\n",
    "    \n",
    "    i = 40817\n",
    "    while i < 40822:\n",
    "        working_df2['firmpdemp'][i] = (working_df2['firmpdemp'][i] * 0.004279356384)\n",
    "        i = i + 1\n",
    "    working_df2['firmpdemp'][40900] = (working_df2['firmpdemp'][40900] * 0.004279356384)\n",
    "    \n",
    "    #Renaming columns\n",
    "    working_df1.rename(columns = {'yibszfi_label':'Years in Business', 'name':'State'}, inplace = True)\n",
    "    working_df2.rename(columns = {'yibszfi_label':'Years in Business', 'name':'State'}, inplace = True)\n",
    "    \n",
    "    #Creating pivots for chart\n",
    "    pivot_df = working_df1.pivot(index='State', columns='Years in Business', values='firmpdemp')\n",
    "    pivot_df1 = working_df2.pivot(index='State', columns='Years in Business', values='firmpdemp')\n",
    "    \n",
    "    #Merging back to one table\n",
    "    pivot_df2 = pd.concat([pivot_df1, pivot_df], axis = 0)\n",
    "    \n",
    "    #Plot info\n",
    "    ordered_df2 = pivot_df2.loc[:,['Firms with less than 2 years in business','Firms with 2 to 3 years in business','Firms with 4 to 5 years in business','Firms with 6 to 10 years in business','Firms with 11 to 15 years in business','Firms with 16 or more years in business']]\n",
    "    fig2 = ordered_df2.plot.bar(alpha = 0.4, ylabel= 'Percentage of Firms', title='Years in Business Percent for Florida and West Virginia',stacked=True, figsize=(18,7))\n",
    "    \n",
    "    #Third plot ETL\n",
    "    working_df=comp_sum_df\n",
    "    \n",
    "    #Dropping rows\n",
    "    working_df = working_df[working_df.race_group_label == 'Total']\n",
    "    working_df = working_df[working_df.industry != 'Total for all sectors']\n",
    "    working_df = working_df[working_df.gender == 'Total']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 2 to 3 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 4 to 5 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 6 to 10 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 11 to 15 years in business']\n",
    "    working_df = working_df[working_df.yibszfi_label != 'Firms with 16 or more years in business']\n",
    "    \n",
    "    #Dropping columns\n",
    "    working_df5 = working_df.drop(['geo_id','industry_code','race_group_label','gender','state','name'], axis = 1)\n",
    "    \n",
    "    #Splitting\n",
    "    working_df6 = working_df5[working_df.yibszfi_label != 'All firms']\n",
    "    working_df7 = working_df5[working_df.yibszfi_label == 'All firms']\n",
    "    \n",
    "    #Getting industry sums for each firm attribute\n",
    "    working_df6 = working_df6.groupby(by = ['industry'])[['firmpdemp']].agg('sum')\n",
    "    working_df7 = working_df7.groupby(by = ['industry'])[['firmpdemp']].agg('sum')\n",
    "    \n",
    "    #Merging with percent\n",
    "    working_df8 = working_df6 / working_df7 * 100\n",
    "    \n",
    "    \n",
    "    #Renaming columns\n",
    "    working_df8.rename(columns = {'firmpdemp':'% of Firms < 2 Years Old'}, inplace = True)\n",
    "    \n",
    "    #Sort\n",
    "    working_df8.sort_values(by = ['% of Firms < 2 Years Old'], inplace = True)\n",
    "    \n",
    "    #Plot\n",
    "    ax = working_df8.plot(figsize = (20,10), title = 'Percentage of Total Businesses Less Than Two Years Old by Industry',kind='bar')\n",
    "    plt.rc('axes',labelsize = 22)\n",
    "    plt.rc('axes',titlesize = 25)\n",
    "    plt.rc('xtick', labelsize=20)\n",
    "    ax.set_ylabel('% of Firms Less than two years old')\n",
    "    ax.set_xlabel('Industry')\n",
    "    plt.xticks(rotation = 45, ha='right')\n",
    "    ax\n",
    "    return fig\n",
    "\n",
    "fig = ryans_visuals(comp_sum_df)\n",
    "fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dcb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jakes_visuals():\n",
    "    #Visual 1: National Firms by Industry and Gender\n",
    "    \n",
    "    workingDF = df_collection[5].copy()\n",
    "    \n",
    "    #I filtered values to look at number of firms by industries, broken down by gender.\n",
    "    #To do this I had to filter to look at 'Total' values for race groups and time the firm was open\n",
    "    workingDF = workingDF[workingDF['firmpdemp'] != 0]\n",
    "    workingDF = workingDF[workingDF['yibszfi_label'] == 'All firms']\n",
    "    workingDF = workingDF[workingDF['race_group_label'] == 'Total']\n",
    "    workingDF = workingDF[workingDF['industry'] != 'Industries not classified']\n",
    "    workingDF = workingDF[workingDF['gender'] != 'Total']\n",
    "    workingDF = workingDF[workingDF['industry'] != 'Total for all sectors']\n",
    "    \n",
    "    #After filtering, unneeded columns are dropped\n",
    "    workingDF.drop(['geo_id', 'name', 'industry_code', 'race_group_label', 'yibszfi_label'], axis = 1, inplace = True)\n",
    "    workingDF = workingDF.sort_values(by = 'firmpdemp', ascending = False)\n",
    "    \n",
    "    #This creates labels for the visual. I generated them separate from the visual so I could add a word-wrap\n",
    "    labels = workingDF['industry'].unique()\n",
    "    labels = [ '\\n'.join(wrap(l, 30)) for l in labels ]\n",
    "    \n",
    "    #Making the plot\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    ax = sns.barplot(data = workingDF, y = 'industry', x = 'firmpdemp', hue = 'gender')\n",
    "    ax.set(xlabel =\"Number of Firms\", ylabel = \"Industry\", title ='Majority Ownership of US Firms by Industry and Gender')\n",
    "    ax.set_yticklabels(labels)\n",
    "    plt.show()\n",
    "    \n",
    "    #Visual 2: National Firms by Industry and Minority Status\n",
    "    workingDF3 = df_collection[5].copy()\n",
    "    \n",
    "    #Filtering values to for firm age and gender, here I'm only interested in minority status and industry\n",
    "    workingDF3 = workingDF3[workingDF3['firmpdemp'] != 0]\n",
    "    workingDF3 = workingDF3[workingDF3['yibszfi_label'] == 'All firms']\n",
    "    workingDF3 = workingDF3[workingDF3['gender'] == 'Total']\n",
    "    workingDF3 = workingDF3[workingDF3['industry'] != 'Industries not classified']\n",
    "    workingDF3 = workingDF3.query('race_group_label  in (\"Nonminority\", \"Minority\")')\n",
    "    workingDF3 = workingDF3[workingDF3['industry'] != 'Total for all sectors']\n",
    "    \n",
    "    #Dropping unneeded columns after using them to filter\n",
    "    workingDF3.drop(['geo_id', 'name', 'industry_code', 'gender', 'yibszfi_label'], axis = 1, inplace = True)\n",
    "    workingDF3 = workingDF3.sort_values(by = 'firmpdemp', ascending = False)\n",
    "    \n",
    "    #Generating labels for the plot and using word wrap\n",
    "    labels3 = workingDF3['industry'].unique()\n",
    "    labels3 = [ '\\n'.join(wrap(l, 30)) for l in labels ]\n",
    "    \n",
    "    #Making the plot\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    ax3 = sns.barplot(data = workingDF3, y = 'industry', x = 'firmpdemp', hue = 'race_group_label')\n",
    "    ax3.set_yticklabels(labels3)\n",
    "    ax3.set(xlabel =\"Number of Firms\", ylabel = \"Industry\", title ='Majority Ownership of US Firms by Industry and Minority Status')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Visual 3: Ratio of Gender Ownership by State for Construction\n",
    "    state_df = df_collection[0].copy()\n",
    "    \n",
    "    #Filtering columns to control for firm age and race group, \n",
    "    #I'm looking at difference in firm ownership by gender and state for the construction industry\n",
    "    state_df = state_df[state_df['industry'] == 'Construction']\n",
    "    state_df = state_df[state_df['gender'] != 'Total']\n",
    "    state_df = state_df[state_df['gender'] != 'Equally male/female']\n",
    "    state_df = state_df[state_df['race_group_label'] == 'Total']\n",
    "    state_df = state_df[state_df['yibszfi_label'] == 'All firms']\n",
    "    \n",
    "    #Dropping unneeded columns\n",
    "    state_df.drop(['geo_id','industry', 'race_group_label','yibszfi_label', 'state', 'emp', 'industry_code', 'payann', 'rcppdemp'], axis = 1, inplace=True)\n",
    "    state_df.sort_values('name', inplace=True)\n",
    "    \n",
    "    #I'm breaking the gender column into 2 separate dataframes\n",
    "    male_df = state_df[state_df['gender'] == 'Male'].copy()\n",
    "    female_df = state_df[state_df['gender'] == 'Female'].copy()\n",
    "    male_df.reset_index(inplace=True)\n",
    "    female_df.reset_index(inplace=True)\n",
    "    \n",
    "    #Making a new dataframe with columns for #male-owned firms and #female-owned firms\n",
    "    newdf = male_df.copy()\n",
    "    newdf.drop('gender', axis = 1, inplace=True)\n",
    "    female_df.drop('gender', axis = 1, inplace=True)\n",
    "    newdf.rename(columns = {'firmpdemp':'Male'}, inplace = True)\n",
    "    female_df.rename(columns = {'firmpdemp':'Female'}, inplace = True)\n",
    "    \n",
    "    #Adding the female-owned firms column\n",
    "    newdf = newdf.merge(female_df, on = 'name')\n",
    "    newdf = newdf[newdf['Male'] != 0]\n",
    "    \n",
    "    #Generating a new column to find the ratio of female-owned firms to male-owned firms\n",
    "    newdf = newdf.assign(RatioFemaleToMale=lambda y: (y['Female'] / y['Male']))\n",
    "    newdf.sort_values('RatioFemaleToMale', ascending = False, inplace = True)\n",
    "    \n",
    "    #Drop unneeded columns\n",
    "    newdf.drop(['Male', 'Female'], axis = 1, inplace = True)\n",
    "    newdf = newdf.head(16)\n",
    "    \n",
    "    #Making the plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax4 = sns.barplot(data = newdf, y = 'name', x = 'RatioFemaleToMale', color = 'orange')\n",
    "    ax4.set(xlabel =\"Ratio of Female Owned Firms to Male Owned Firms\", \n",
    "    ylabel = \"State\", title ='Majority Ownership of US Firms by Gender and State')\n",
    "    plt.show()\n",
    "jakes_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a1b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
